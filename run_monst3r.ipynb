{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b433b24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path '/root/jupyter/monst3r' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "!git clone --recursive https://github.com/junyi42/monst3r /root/jupyter/monst3r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c04b2c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb4cf4ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/__modal/volumes/vo-05VlmA5Lclgm1HklUu8tDq/monst3r/croco/models/curope\n",
      "running build_ext\n",
      "W1014 17:24:08.508000 30 site-packages/torch/utils/cpp_extension.py:615] Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n",
      "W1014 17:24:09.083000 30 site-packages/torch/utils/cpp_extension.py:507] The detected CUDA version (12.1) has a minor version mismatch with the version that was used to compile PyTorch (12.8). Most likely this shouldn't be a problem.\n",
      "W1014 17:24:09.084000 30 site-packages/torch/utils/cpp_extension.py:517] There are no clang++ version bounds defined for CUDA version 12.1\n",
      "building 'curope' extension\n",
      "creating build\n",
      "creating build/temp.linux-x86_64-cpython-310\n",
      "clang -pthread -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -fPIC -I/tools/deps/include -I/tools/deps/include/ncursesw -I/tools/deps/libedit/include -g0 -fPIC -I/usr/local/lib/python3.10/site-packages/torch/include -I/usr/local/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/usr/local/cuda/include -I/usr/local/include/python3.10 -c curope.cpp -o build/temp.linux-x86_64-cpython-310/curope.o -O3 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1018\\\" -DTORCH_EXTENSION_NAME=curope -std=c++17\n",
      "/usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.10/site-packages/torch/include -I/usr/local/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/usr/local/cuda/include -I/usr/local/include/python3.10 -c kernels.cu -o build/temp.linux-x86_64-cpython-310/kernels.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 --ptxas-options=-v --use_fast_math -gencode arch=compute_70,code=sm_70 -gencode arch=compute_75,code=sm_75 -gencode arch=compute_80,code=sm_80 -gencode arch=compute_86,code=sm_86 -gencode arch=compute_90,code=sm_90 -gencode arch=compute_100,code=sm_100 -gencode arch=compute_120,code=sm_120 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1018\\\" -DTORCH_EXTENSION_NAME=curope -std=c++17\n",
      "nvcc fatal   : Unsupported gpu architecture 'compute_100'\n",
      "error: command '/usr/local/cuda/bin/nvcc' failed with exit code 1\n"
     ]
    }
   ],
   "source": [
    "# DUST3R relies on RoPE positional embeddings for which you can compile some cuda kernels for faster runtime.\n",
    "%cd /root/jupyter/monst3r/croco/models/curope/\n",
    "!python setup.py build_ext --inplace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc25a26a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2023 NVIDIA Corporation\n",
      "Built on Mon_Apr__3_17:16:06_PDT_2023\n",
      "Cuda compilation tools, release 12.1, V12.1.105\n",
      "Build cuda_12.1.r12.1/compiler.32688072_0\n"
     ]
    }
   ],
   "source": [
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3896357b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_3D_model_from_scene(outdir, silent, scene, min_conf_thr=3, as_pointcloud=False, mask_sky=False,\n",
    "                            clean_depth=False, transparent_cams=False, cam_size=0.05, show_cam=True, save_name=None, thr_for_init_conf=True):\n",
    "    \"\"\"\n",
    "    extract 3D_model (glb file) from a reconstructed scene\n",
    "    \"\"\"\n",
    "    if scene is None:\n",
    "        return None\n",
    "    # post processes\n",
    "    if clean_depth:\n",
    "        scene = scene.clean_pointcloud()\n",
    "    if mask_sky:\n",
    "        scene = scene.mask_sky()\n",
    "\n",
    "    # get optimized values from scene\n",
    "    rgbimg = scene.imgs\n",
    "    focals = scene.get_focals().cpu()\n",
    "    cams2world = scene.get_im_poses().cpu()\n",
    "    # 3D pointcloud from depthmap, poses and intrinsics\n",
    "    pts3d = to_numpy(scene.get_pts3d(raw_pts=True))\n",
    "    scene.min_conf_thr = min_conf_thr\n",
    "    scene.thr_for_init_conf = thr_for_init_conf\n",
    "    msk = to_numpy(scene.get_masks())\n",
    "    cmap = pl.get_cmap('viridis')\n",
    "    cam_color = [cmap(i/len(rgbimg))[:3] for i in range(len(rgbimg))]\n",
    "    cam_color = [(255*c[0], 255*c[1], 255*c[2]) for c in cam_color]\n",
    "    return convert_scene_output_to_glb(outdir, rgbimg, pts3d, msk, focals, cams2world, as_pointcloud=as_pointcloud,\n",
    "                                        transparent_cams=transparent_cams, cam_size=cam_size, show_cam=show_cam, silent=silent, save_name=save_name,\n",
    "                                        cam_color=cam_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf4f058",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_reconstructed_scene(args, outdir, model, device, silent, image_size, schedule, niter, min_conf_thr,\n",
    "                            as_pointcloud, mask_sky, clean_depth, transparent_cams, cam_size, show_cam, scenegraph_type, winsize, refid, \n",
    "                            seq_name, new_model_weights, temporal_smoothing_weight, translation_weight, shared_focal, \n",
    "                            flow_loss_weight, flow_loss_start_iter, flow_loss_threshold, use_gt_mask, fps, num_frames):\n",
    "    \"\"\"\n",
    "    from a list of images, run dust3r inference, global aligner.\n",
    "    then run get_3D_model_from_scene\n",
    "    \"\"\"\n",
    "    translation_weight = float(translation_weight)\n",
    "    if new_model_weights != args.weights:\n",
    "        model = AsymmetricCroCo3DStereo.from_pretrained(new_model_weights).to(device)\n",
    "    model.eval()\n",
    "    if seq_name != \"NULL\":\n",
    "        dynamic_mask_path = f'data/davis/DAVIS/masked_images/480p/{seq_name}'\n",
    "    else:\n",
    "        dynamic_mask_path = None\n",
    "\n",
    "    imgs = torch.load(\"/root/jupyter/data/preprocessed_data.pth\")\n",
    "        \n",
    "    if len(imgs) == 1:\n",
    "        imgs = [imgs[0], copy.deepcopy(imgs[0])]\n",
    "        imgs[1]['idx'] = 1\n",
    "    if scenegraph_type == \"swin\" or scenegraph_type == \"swinstride\" or scenegraph_type == \"swin2stride\":\n",
    "        scenegraph_type = scenegraph_type + \"-\" + str(winsize) + \"-noncyclic\"\n",
    "    elif scenegraph_type == \"oneref\":\n",
    "        scenegraph_type = scenegraph_type + \"-\" + str(refid)\n",
    "\n",
    "    pairs = make_pairs(imgs, scene_graph=scenegraph_type, prefilter=None, symmetrize=True)\n",
    "    output = inference(pairs, model, device, batch_size=args.batch_size, verbose=not silent)\n",
    "    # TODO YYJ del model\n",
    "    if len(imgs) > 2:\n",
    "        mode = GlobalAlignerMode.PointCloudOptimizer\n",
    "        scene = global_aligner(output, device=device, mode=mode, verbose=not silent, shared_focal = shared_focal, temporal_smoothing_weight=temporal_smoothing_weight, translation_weight=translation_weight,\n",
    "                               flow_loss_weight=flow_loss_weight, flow_loss_start_epoch=flow_loss_start_iter, flow_loss_thre=flow_loss_threshold, use_self_mask=not use_gt_mask,\n",
    "                               num_total_iter=niter, empty_cache= len(filelist) > 72, batchify=not (args.not_batchify or args.window_wise),\n",
    "                               window_wise=args.window_wise, window_size=args.window_size, window_overlap_ratio=args.window_overlap_ratio,\n",
    "                               prev_video_results=prev_video_results)\n",
    "    else:\n",
    "        mode = GlobalAlignerMode.PairViewer\n",
    "        scene = global_aligner(output, device=device, mode=mode, verbose=not silent)\n",
    "    lr = 0.01\n",
    "\n",
    "    if mode == GlobalAlignerMode.PointCloudOptimizer:\n",
    "        if args.window_wise:\n",
    "            scene.compute_window_wise_alignment(init='mst', niter=niter, schedule=schedule, lr=lr)\n",
    "        else:\n",
    "            scene.compute_global_alignment(init='mst', niter=niter, schedule=schedule, lr=lr)\n",
    "\n",
    "    if args.window_wise and args.prev_output_dir is not None:\n",
    "        scene.clean_prev_results()\n",
    "        \n",
    "    save_folder = f'{args.output_dir}/{seq_name}'  #default is 'demo_tmp/NULL'\n",
    "    os.makedirs(save_folder, exist_ok=True)\n",
    "    outfile = get_3D_model_from_scene(save_folder, silent, scene, min_conf_thr, as_pointcloud, mask_sky,\n",
    "                            clean_depth, transparent_cams, cam_size, show_cam)\n",
    "\n",
    "    poses = scene.save_tum_poses(f'{save_folder}/pred_traj.txt')\n",
    "    K = scene.save_intrinsics(f'{save_folder}/pred_intrinsics.txt')\n",
    "    depth_maps = scene.save_depth_maps(save_folder)\n",
    "    dynamic_masks = scene.save_dynamic_masks(save_folder)\n",
    "    conf = scene.save_conf_maps(save_folder)\n",
    "    init_conf = scene.save_init_conf_maps(save_folder)\n",
    "    rgbs = scene.save_rgb_imgs(save_folder)\n",
    "    enlarge_seg_masks(save_folder, kernel_size=5 if use_gt_mask else 3) \n",
    "\n",
    "    # also return rgb, depth and confidence imgs\n",
    "    # depth is normalized with the max value for all images\n",
    "    # we apply the jet colormap on the confidence maps\n",
    "    rgbimg = scene.imgs\n",
    "    depths = to_numpy(scene.get_depthmaps())\n",
    "    confs = to_numpy([c for c in scene.im_conf])\n",
    "    init_confs = to_numpy([c for c in scene.init_conf_maps])\n",
    "    cmap = pl.get_cmap('jet')\n",
    "    depths_max = max([d.max() for d in depths])\n",
    "    depths = [cmap(d/depths_max) for d in depths]\n",
    "    confs_max = max([d.max() for d in confs])\n",
    "    confs = [cmap(d/confs_max) for d in confs]\n",
    "    init_confs_max = max([d.max() for d in init_confs])\n",
    "    init_confs = [cmap(d/init_confs_max) for d in init_confs]\n",
    "\n",
    "    imgs = []\n",
    "    for i in range(len(rgbimg)):\n",
    "        imgs.append(rgbimg[i])\n",
    "        imgs.append(rgb(depths[i]))\n",
    "        imgs.append(rgb(confs[i]))\n",
    "        imgs.append(rgb(init_confs[i]))\n",
    "\n",
    "    # if two images, and the shape is same, we can compute the dynamic mask\n",
    "    if len(rgbimg) == 2 and rgbimg[0].shape == rgbimg[1].shape:\n",
    "        motion_mask_thre = 0.35\n",
    "        error_map = get_dynamic_mask_from_pairviewer(scene, both_directions=True, output_dir=args.output_dir, motion_mask_thre=motion_mask_thre)\n",
    "        # imgs.append(rgb(error_map))\n",
    "        # apply threshold on the error map\n",
    "        normalized_error_map = (error_map - error_map.min()) / (error_map.max() - error_map.min())\n",
    "        error_map_max = normalized_error_map.max()\n",
    "        error_map = cmap(normalized_error_map/error_map_max)\n",
    "        imgs.append(rgb(error_map))\n",
    "        binary_error_map = (normalized_error_map > motion_mask_thre).astype(np.uint8)\n",
    "        imgs.append(rgb(binary_error_map*255))\n",
    "\n",
    "    return scene, outfile, imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "60e2de7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!sed -i \"s/torch.load(model_path, map_location='cpu')/torch.load(model_path, map_location='cpu', weights_only=False)/\" /root/jupyter/monst3r/dust3r/model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7c8e595",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import torch\n",
    "torch.serialization.add_safe_globals([argparse.Namespace])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aea759a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34m__pycache__\u001b[0m/  host_nb.py  \u001b[01;36mjupyter\u001b[0m@\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb60633b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LICENSE       \u001b[0m\u001b[01;34mdatasets_preprocess\u001b[0m/  requirements.txt\n",
      "README.md     demo.py               requirements_optional.txt\n",
      "\u001b[01;34massets\u001b[0m/       \u001b[01;34mdemo_data\u001b[0m/            \u001b[01;34mthird_party\u001b[0m/\n",
      "\u001b[01;34mcheckpoints\u001b[0m/  depth_metric.ipynb    \u001b[01;34mviser\u001b[0m/\n",
      "\u001b[01;34mcroco\u001b[0m/        \u001b[01;34mdust3r\u001b[0m/\n",
      "\u001b[01;34mdata\u001b[0m/         launch.py\n"
     ]
    }
   ],
   "source": [
    "%ls /root/jupyter/monst3r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54810b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/__modal/volumes/vo-05VlmA5Lclgm1HklUu8tDq/monst3r\n",
      "\u001b[93mInitialized new /root/.evo/settings.json\u001b[39m\n",
      "Warning, cannot find cuda-compiled version of RoPE2D, using a slow pytorch version instead\n",
      "/__modal/volumes/vo-05VlmA5Lclgm1HklUu8tDq/monst3r/dust3r/cloud_opt/base_opt.py:399: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @torch.cuda.amp.autocast(enabled=False)\n",
      "/__modal/volumes/vo-05VlmA5Lclgm1HklUu8tDq/monst3r/dust3r/cloud_opt/base_opt.py:416: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @torch.cuda.amp.autocast(enabled=False)\n",
      "... loading model from checkpoints/MonST3R_PO-TA-S-W_ViTLarge_BaseDecoder_512_dpt.pth\n",
      "instantiating : AsymmetricCroCo3DStereo(pos_embed='RoPE100', patch_embed_cls='PatchEmbedDust3R', img_size=(512, 512), head_type='dpt', output_mode='pts3d', depth_mode=('exp', -inf, inf), conf_mode=('exp', 1, inf), enc_embed_dim=1024, enc_depth=24, enc_num_heads=16, dec_embed_dim=768, dec_depth=12, dec_num_heads=12, freeze='encoder', landscape_only=False)\n",
      "Freezing encoder parameters\n",
      "<All keys matched successfully>\n",
      "Outputting stuff in /root/jupyter/data/demo_tmp\n",
      ">> Loading a list of 242 items\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0041.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0042.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0043.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0044.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0045.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0046.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0047.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0048.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0049.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0050.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0051.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0052.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0053.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0054.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0055.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0056.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0057.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0058.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0059.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0060.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0061.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0062.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0063.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0064.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0065.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0066.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0067.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0068.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0069.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0070.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0071.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0072.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0073.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0074.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0075.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0076.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0077.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0078.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0079.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0080.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0081.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0082.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0083.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0084.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0085.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0086.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0087.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0088.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0089.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0090.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0091.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0092.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0093.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0094.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0095.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0096.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0097.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0098.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0099.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0100.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0101.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0102.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0103.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0104.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0105.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0106.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0107.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0108.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0109.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0110.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0111.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0112.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0113.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0114.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0115.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0116.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0117.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0118.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0119.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0120.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0121.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0122.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0123.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0124.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0125.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0126.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0127.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0128.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0129.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0130.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0131.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0132.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0133.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0134.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0135.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0136.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0137.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0138.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0139.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0140.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0141.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0142.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0143.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0144.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0145.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0146.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0147.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0148.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0149.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0150.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0151.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0152.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0153.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0154.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0155.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0156.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0157.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0158.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0159.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0160.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0161.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0162.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0163.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0164.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0165.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0166.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0167.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0168.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0169.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0170.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0171.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0172.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0173.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0174.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0175.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0176.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0177.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0178.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0179.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0180.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0181.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0182.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0183.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0184.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0185.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0186.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0187.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0188.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0189.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0190.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0191.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0192.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0193.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0194.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0195.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0196.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0197.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0200.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0201.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0202.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0203.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0204.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0205.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0206.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0207.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0208.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0209.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0210.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0211.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0212.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0213.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0214.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0215.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0216.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0217.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0218.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0219.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0220.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0221.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0222.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0223.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0224.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0225.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0226.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0227.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0228.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0229.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0230.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0231.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0232.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0233.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0234.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0235.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0236.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0237.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0238.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0239.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0240.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0241.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0242.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0243.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0244.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0245.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0246.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0247.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0248.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0249.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0250.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0251.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0252.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0253.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0254.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0255.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0256.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0257.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0258.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0259.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0260.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0261.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0262.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0263.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0264.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0265.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0266.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0267.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0268.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0269.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0270.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0271.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0272.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0273.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0274.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0275.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0276.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0277.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0278.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0279.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0280.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0281.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0282.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0283.JPG with resolution 512x384 --> 512x384\n",
      " - Adding /root/jupyter/data/resized_classified/iphone6/landscape/IMG_0284.JPG with resolution 512x384 --> 512x384\n",
      " (Found 242 images)\n",
      ">> Inference with model on 2370 image pairs\n",
      "  0%|                                                   | 0/149 [00:00<?, ?it/s]/__modal/volumes/vo-05VlmA5Lclgm1HklUu8tDq/monst3r/dust3r/inference.py:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=bool(use_amp)):\n",
      "/__modal/volumes/vo-05VlmA5Lclgm1HklUu8tDq/monst3r/dust3r/model.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=False):\n",
      "/__modal/volumes/vo-05VlmA5Lclgm1HklUu8tDq/monst3r/dust3r/inference.py:74: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=False):\n",
      "100%|█████████████████████████████████████████| 149/149 [01:57<00:00,  1.27it/s]\n",
      "precomputing flow...\n",
      "Downloading: \"https://download.pytorch.org/models/resnet34-b627a593.pth\" to /root/.cache/torch/hub/checkpoints/resnet34-b627a593.pth\n",
      "100%|███████████████████████████████████████| 83.3M/83.3M [00:00<00:00, 108MB/s]\n",
      "Loaded pretrained RAFT model from third_party/RAFT/models/Tartan-C-T-TSKH-spring540x960-M.pth\n",
      "  0%|                                                   | 0/198 [00:00<?, ?it/s]/usr/local/lib/python3.10/site-packages/torch/functional.py:554: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /pytorch/aten/src/ATen/native/TensorShape.cpp:4322.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "100%|█████████████████████████████████████████| 198/198 [01:53<00:00,  1.74it/s]\n",
      "flow precomputed\n",
      "100%|███████████████████████████████████████| 1185/1185 [06:33<00:00,  3.01it/s]\n",
      "/monst3r/third_party/sam2/sam2/sam2_video_predictor.py:962: UserWarning: cannot import name '_C' from 'sam2' (/monst3r/third_party/sam2/sam2/__init__.py)\n",
      "\n",
      "Skipping the post-processing step due to the error above. You can still use SAM 2 and it's OK to ignore the error above, although some post-processing functionality may be limited (which doesn't affect the results in most cases; see https://github.com/facebookresearch/sam2/blob/main/INSTALL.md).\n",
      "  pred_masks_gpu = fill_holes_in_mask_scores(\n",
      "propagate in video: 100%|█████████████████████| 242/242 [00:13<00:00, 18.03it/s]\n",
      "propagate in video: 100%|█████████████████████| 242/242 [00:13<00:00, 17.99it/s]\n",
      " init edge (225*,224*) score=np.float64(114.2791976928711)\n",
      " init edge (227*,224) score=np.float64(105.69831085205078)\n",
      " init edge (226*,225) score=np.float64(59.1413459777832)\n",
      " init edge (228*,227) score=np.float64(45.218048095703125)\n",
      " init edge (229*,228) score=np.float64(43.31183624267578)\n",
      " init edge (230*,229) score=np.float64(29.479902267456055)\n",
      " init edge (226,223*) score=np.float64(16.959421157836914)\n",
      " init edge (224,217*) score=np.float64(2.796886920928955)\n",
      " init edge (228,237*) score=np.float64(2.5345959663391113)\n",
      " init edge (230,231*) score=np.float64(36.4488525390625)\n",
      " init edge (216*,217) score=np.float64(13.0300931930542)\n",
      " init edge (231,232*) score=np.float64(12.764418601989746)\n",
      " init edge (238*,237) score=np.float64(11.043081283569336)\n",
      " init edge (217,218*) score=np.float64(7.910083770751953)\n",
      " init edge (238,239*) score=np.float64(7.059238433837891)\n",
      " init edge (219*,218) score=np.float64(5.04136848449707)\n",
      " init edge (211*,218) score=np.float64(3.3746707439422607)\n",
      " init edge (233*,232) score=np.float64(43.48978805541992)\n",
      " init edge (212*,211) score=np.float64(19.4813175201416)\n",
      " init edge (213*,212) score=np.float64(19.13009262084961)\n",
      " init edge (240*,239) score=np.float64(7.6316680908203125)\n",
      " init edge (211,210*) score=np.float64(6.994009494781494)\n",
      " init edge (220*,219) score=np.float64(5.566760540008545)\n",
      " init edge (213,214*) score=np.float64(5.440984725952148)\n",
      " init edge (212,207*) score=np.float64(3.1970086097717285)\n",
      " init edge (202*,207) score=np.float64(2.8354415893554688)\n",
      " init edge (235*,240) score=np.float64(1.9285200834274292)\n",
      " init edge (202,201*) score=np.float64(39.91266632080078)\n",
      " init edge (202,203*) score=np.float64(18.99722671508789)\n",
      " init edge (220,221*) score=np.float64(18.360939025878906)\n",
      " init edge (206*,207) score=np.float64(15.798722267150879)\n",
      " init edge (214,215*) score=np.float64(12.427582740783691)\n",
      " init edge (236*,235) score=np.float64(11.503541946411133)\n",
      " init edge (206,205*) score=np.float64(11.281794548034668)\n",
      " init edge (221,222*) score=np.float64(10.879864692687988)\n",
      " init edge (206,197*) score=np.float64(2.6437437534332275)\n",
      " init edge (198*,197) score=np.float64(2.3291163444519043)\n",
      " init edge (206,199*) score=np.float64(2.3173716068267822)\n",
      " init edge (235,234*) score=np.float64(1.9832297563552856)\n",
      " init edge (234,241*) score=np.float64(1.750849723815918)\n",
      " init edge (206,209*) score=np.float64(17.5462646484375)\n",
      " init edge (199,200*) score=np.float64(14.309346199035645)\n",
      " init edge (205,204*) score=np.float64(13.102306365966797)\n",
      " init edge (208*,209) score=np.float64(11.36841106414795)\n",
      " init edge (188*,197) score=np.float64(2.6893656253814697)\n",
      " init edge (189*,188) score=np.float64(2.2602274417877197)\n",
      " init edge (189,190*) score=np.float64(5.076755523681641)\n",
      " init edge (186*,189) score=np.float64(2.7218387126922607)\n",
      " init edge (186,193*) score=np.float64(2.4061896800994873)\n",
      " init edge (190,191*) score=np.float64(8.776583671569824)\n",
      " init edge (191,192*) score=np.float64(7.499110221862793)\n",
      " init edge (193,194*) score=np.float64(4.490198135375977)\n",
      " init edge (186,187*) score=np.float64(3.561218738555908)\n",
      " init edge (186,185*) score=np.float64(3.337998390197754)\n",
      " init edge (184*,185) score=np.float64(8.224662780761719)\n",
      " init edge (195*,194) score=np.float64(6.630239963531494)\n",
      " init edge (184,177*) score=np.float64(3.7628486156463623)\n",
      " init edge (195,196*) score=np.float64(2.0771472454071045)\n",
      " init edge (176*,177) score=np.float64(28.499059677124023)\n",
      " init edge (175*,176) score=np.float64(27.12118148803711)\n",
      " init edge (175,174*) score=np.float64(27.00043296813965)\n",
      " init edge (172*,175) score=np.float64(26.315059661865234)\n",
      " init edge (172,171*) score=np.float64(25.763294219970703)\n",
      " init edge (173*,174) score=np.float64(23.090776443481445)\n",
      " init edge (170*,171) score=np.float64(22.995893478393555)\n",
      " init edge (169*,170) score=np.float64(22.84945297241211)\n",
      " init edge (177,178*) score=np.float64(22.65467071533203)\n",
      " init edge (178,179*) score=np.float64(12.063575744628906)\n",
      " init edge (179,180*) score=np.float64(9.086301803588867)\n",
      " init edge (180,183*) score=np.float64(4.57197904586792)\n",
      " init edge (179,182*) score=np.float64(3.53558349609375)\n",
      " init edge (169,168*) score=np.float64(22.994550704956055)\n",
      " init edge (168,167*) score=np.float64(18.62727165222168)\n",
      " init edge (181*,180) score=np.float64(10.644856452941895)\n",
      " init edge (162*,167) score=np.float64(24.960857391357422)\n",
      " init edge (161*,162) score=np.float64(4.082769870758057)\n",
      " init edge (162,165*) score=np.float64(35.329349517822266)\n",
      " init edge (166*,165) score=np.float64(33.09805679321289)\n",
      " init edge (163*,166) score=np.float64(32.20726776123047)\n",
      " init edge (160*,161) score=np.float64(11.937948226928711)\n",
      " init edge (164*,163) score=np.float64(34.88120651245117)\n",
      " init edge (160,159*) score=np.float64(13.088767051696777)\n",
      " init edge (158*,159) score=np.float64(12.018827438354492)\n",
      " init edge (152*,159) score=np.float64(3.3183205127716064)\n",
      " init edge (149*,152) score=np.float64(30.998960494995117)\n",
      " init edge (158,157*) score=np.float64(14.712760925292969)\n",
      " init edge (142*,149) score=np.float64(36.529170989990234)\n",
      " init edge (149,150*) score=np.float64(34.702728271484375)\n",
      " init edge (142,151*) score=np.float64(34.32237243652344)\n",
      " init edge (140*,149) score=np.float64(33.575157165527344)\n",
      " init edge (139*,142) score=np.float64(32.62487030029297)\n",
      " init edge (142,147*) score=np.float64(31.495647430419922)\n",
      " init edge (136*,139) score=np.float64(30.930156707763672)\n",
      " init edge (137*,140) score=np.float64(28.82587432861328)\n",
      " init edge (136,133*) score=np.float64(5.505876064300537)\n",
      " init edge (140,143*) score=np.float64(38.37318420410156)\n",
      " init edge (143,146*) score=np.float64(35.10346984863281)\n",
      " init edge (138*,143) score=np.float64(33.27946090698242)\n",
      " init edge (145*,146) score=np.float64(33.173458099365234)\n",
      " init edge (145,148*) score=np.float64(32.04239273071289)\n",
      " init edge (133,132*) score=np.float64(27.40382194519043)\n",
      " init edge (148,153*) score=np.float64(24.605487823486328)\n",
      " init edge (135*,138) score=np.float64(22.169275283813477)\n",
      " init edge (133,134*) score=np.float64(16.242706298828125)\n",
      " init edge (156*,153) score=np.float64(8.103755950927734)\n",
      " init edge (138,141*) score=np.float64(36.063995361328125)\n",
      " init edge (131*,132) score=np.float64(34.83136749267578)\n",
      " init edge (141,144*) score=np.float64(32.72356033325195)\n",
      " init edge (131,130*) score=np.float64(26.171022415161133)\n",
      " init edge (155*,156) score=np.float64(8.221078872680664)\n",
      " init edge (127*,130) score=np.float64(40.28662109375)\n",
      " init edge (127,128*) score=np.float64(36.262962341308594)\n",
      " init edge (154*,155) score=np.float64(15.229010581970215)\n",
      " init edge (128,129*) score=np.float64(47.20188903808594)\n",
      " init edge (125*,128) score=np.float64(44.79825210571289)\n",
      " init edge (126*,127) score=np.float64(42.47487258911133)\n",
      " init edge (126,123*) score=np.float64(29.069110870361328)\n",
      " init edge (124*,125) score=np.float64(28.243030548095703)\n",
      " init edge (123,122*) score=np.float64(26.469219207763672)\n",
      " init edge (124,121*) score=np.float64(24.644153594970703)\n",
      " init edge (121,120*) score=np.float64(20.219606399536133)\n",
      " init edge (124,119*) score=np.float64(16.458370208740234)\n",
      " init edge (115*,120) score=np.float64(21.63800048828125)\n",
      " init edge (114*,115) score=np.float64(18.67435073852539)\n",
      " init edge (119,116*) score=np.float64(18.347129821777344)\n",
      " init edge (116,113*) score=np.float64(17.99452781677246)\n",
      " init edge (117*,116) score=np.float64(16.986949920654297)\n",
      " init edge (115,118*) score=np.float64(15.986824035644531)\n",
      " init edge (112*,113) score=np.float64(22.910839080810547)\n",
      " init edge (112,111*) score=np.float64(15.755478858947754)\n",
      " init edge (108*,111) score=np.float64(10.024542808532715)\n",
      " init edge (105*,108) score=np.float64(6.3968400955200195)\n",
      " init edge (104*,105) score=np.float64(3.5945792198181152)\n",
      " init edge (99*,108) score=np.float64(2.847956895828247)\n",
      " init edge (96*,99) score=np.float64(25.200937271118164)\n",
      " init edge (99,100*) score=np.float64(22.459733963012695)\n",
      " init edge (96,101*) score=np.float64(22.0968017578125)\n",
      " init edge (110*,111) score=np.float64(18.99382781982422)\n",
      " init edge (91*,96) score=np.float64(14.51921558380127)\n",
      " init edge (91,92*) score=np.float64(12.652482032775879)\n",
      " init edge (90*,99) score=np.float64(12.013745307922363)\n",
      " init edge (89*,96) score=np.float64(10.433476448059082)\n",
      " init edge (89,84*) score=np.float64(9.650370597839355)\n",
      " init edge (89,86*) score=np.float64(9.423139572143555)\n",
      " init edge (109*,110) score=np.float64(9.141983985900879)\n",
      " init edge (105,106*) score=np.float64(8.797409057617188)\n",
      " init edge (106,107*) score=np.float64(5.361051082611084)\n",
      " init edge (102*,101) score=np.float64(3.348618984222412)\n",
      " init edge (97*,100) score=np.float64(27.21751594543457)\n",
      " init edge (97,98*) score=np.float64(20.544801712036133)\n",
      " init edge (102,103*) score=np.float64(17.690250396728516)\n",
      " init edge (94*,97) score=np.float64(16.067672729492188)\n",
      " init edge (93*,94) score=np.float64(14.898658752441406)\n",
      " init edge (95*,98) score=np.float64(13.630921363830566)\n",
      " init edge (84,83*) score=np.float64(11.680432319641113)\n",
      " init edge (88*,93) score=np.float64(10.333708763122559)\n",
      " init edge (88,87*) score=np.float64(10.024658203125)\n",
      " init edge (88,85*) score=np.float64(11.248377799987793)\n",
      " init edge (82*,85) score=np.float64(10.309615135192871)\n",
      " init edge (82,81*) score=np.float64(8.787460327148438)\n",
      " init edge (80*,85) score=np.float64(11.260080337524414)\n",
      " init edge (78*,81) score=np.float64(9.811071395874023)\n",
      " init edge (78,77*) score=np.float64(9.275566101074219)\n",
      " init edge (74*,77) score=np.float64(7.377913475036621)\n",
      " init edge (73*,74) score=np.float64(16.854183197021484)\n",
      " init edge (75*,74) score=np.float64(15.005457878112793)\n",
      " init edge (79*,80) score=np.float64(12.086136817932129)\n",
      " init edge (75,76*) score=np.float64(17.62894058227539)\n",
      " init edge (72*,73) score=np.float64(16.88188934326172)\n",
      " init edge (71*,72) score=np.float64(13.081265449523926)\n",
      " init edge (66*,71) score=np.float64(14.996572494506836)\n",
      " init edge (64*,71) score=np.float64(14.507511138916016)\n",
      " init edge (61*,64) score=np.float64(11.92488956451416)\n",
      " init edge (61,62*) score=np.float64(32.46245193481445)\n",
      " init edge (62,63*) score=np.float64(23.954574584960938)\n",
      " init edge (60*,61) score=np.float64(19.26238250732422)\n",
      " init edge (62,65*) score=np.float64(17.759267807006836)\n",
      " init edge (66,67*) score=np.float64(16.58517837524414)\n",
      " init edge (60,55*) score=np.float64(14.178898811340332)\n",
      " init edge (56*,55) score=np.float64(25.487110137939453)\n",
      " init edge (56,53*) score=np.float64(21.89626121520996)\n",
      " init edge (56,51*) score=np.float64(18.76222801208496)\n",
      " init edge (55,54*) score=np.float64(17.7882022857666)\n",
      " init edge (58*,53) score=np.float64(17.577356338500977)\n",
      " init edge (67,68*) score=np.float64(17.263242721557617)\n",
      " init edge (58,57*) score=np.float64(15.883671760559082)\n",
      " init edge (68,69*) score=np.float64(14.581149101257324)\n",
      " init edge (69,70*) score=np.float64(14.018710136413574)\n",
      " init edge (59*,56) score=np.float64(25.598718643188477)\n",
      " init edge (51,50*) score=np.float64(25.03510284423828)\n",
      " init edge (59,52*) score=np.float64(23.246471405029297)\n",
      " init edge (49*,50) score=np.float64(20.66457748413086)\n",
      " init edge (49,48*) score=np.float64(19.314865112304688)\n",
      " init edge (45*,48) score=np.float64(2.3905773162841797)\n",
      " init edge (44*,45) score=np.float64(46.60292053222656)\n",
      " init edge (47*,48) score=np.float64(20.096982955932617)\n",
      " init edge (43*,44) score=np.float64(2.8452885150909424)\n",
      " init edge (47,40*) score=np.float64(1.8626830577850342)\n",
      " init edge (47,46*) score=np.float64(22.251502990722656)\n",
      " init edge (42*,43) score=np.float64(4.0131306648254395)\n",
      " init edge (46,37*) score=np.float64(2.2048165798187256)\n",
      " init edge (42,41*) score=np.float64(4.77652645111084)\n",
      " init edge (38*,37) score=np.float64(4.29387903213501)\n",
      " init edge (36*,37) score=np.float64(3.9093382358551025)\n",
      " init edge (38,39*) score=np.float64(7.006948471069336)\n",
      " init edge (35*,36) score=np.float64(6.504848480224609)\n",
      " init edge (34*,35) score=np.float64(8.606586456298828)\n",
      " init edge (34,33*) score=np.float64(11.03797435760498)\n",
      " init edge (33,32*) score=np.float64(11.722034454345703)\n",
      " init edge (27*,32) score=np.float64(10.725761413574219)\n",
      " init edge (27,30*) score=np.float64(15.73297119140625)\n",
      " init edge (31*,32) score=np.float64(12.569225311279297)\n",
      " init edge (23*,30) score=np.float64(10.386774063110352)\n",
      " init edge (22*,23) score=np.float64(7.16551399230957)\n",
      " init edge (26*,23) score=np.float64(15.289423942565918)\n",
      " init edge (22,25*) score=np.float64(12.52548885345459)\n",
      " init edge (23,28*) score=np.float64(12.359906196594238)\n",
      " init edge (25,24*) score=np.float64(20.197160720825195)\n",
      " init edge (29*,24) score=np.float64(7.611670970916748)\n",
      " init edge (24,21*) score=np.float64(3.278069496154785)\n",
      " init edge (29,20*) score=np.float64(3.0355775356292725)\n",
      " init edge (19*,20) score=np.float64(22.0981388092041)\n",
      " init edge (16*,19) score=np.float64(3.633767604827881)\n",
      " init edge (10*,19) score=np.float64(2.79945707321167)\n",
      " init edge (11*,16) score=np.float64(2.349822998046875)\n",
      " init edge (18*,19) score=np.float64(23.43896484375)\n",
      " init edge (17*,18) score=np.float64(17.76941680908203)\n",
      " init edge (9*,10) score=np.float64(13.225974082946777)\n",
      " init edge (12*,17) score=np.float64(2.3683133125305176)\n",
      " init edge (9,8*) score=np.float64(50.21217346191406)\n",
      " init edge (12,13*) score=np.float64(7.8181939125061035)\n",
      " init edge (13,14*) score=np.float64(7.660104751586914)\n",
      " init edge (14,15*) score=np.float64(7.057276725769043)\n",
      " init edge (7*,8) score=np.float64(5.497599124908447)\n",
      " init edge (12,5*) score=np.float64(2.4872865676879883)\n",
      " init edge (6*,5) score=np.float64(2.707132339477539)\n",
      " init edge (6,1*) score=np.float64(2.4591100215911865)\n",
      " init edge (6,3*) score=np.float64(2.2211530208587646)\n",
      " init edge (2*,1) score=np.float64(9.184342384338379)\n",
      " init edge (0*,1) score=np.float64(6.051933288574219)\n",
      " init edge (4*,3) score=np.float64(2.7084109783172607)\n",
      "Global alignement - optimizing for:\n",
      "['pw_poses', 'im_depthmaps', 'im_poses', 'im_focals']\n",
      "  0%|                                                   | 0/300 [00:00<?, ?it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"/__modal/volumes/vo-05VlmA5Lclgm1HklUu8tDq/monst3r/demo.py\", line 424, in <module>\n",
      "    scene, outfile, imgs = recon_fun(\n",
      "  File \"/__modal/volumes/vo-05VlmA5Lclgm1HklUu8tDq/monst3r/demo.py\", line 146, in get_reconstructed_scene\n",
      "    scene.compute_global_alignment(init='mst', niter=niter, schedule=schedule, lr=lr)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/torch/amp/autocast_mode.py\", line 44, in decorate_autocast\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/__modal/volumes/vo-05VlmA5Lclgm1HklUu8tDq/monst3r/dust3r/cloud_opt/base_opt.py\", line 414, in compute_global_alignment\n",
      "    return global_alignment_loop(self, **kw)\n",
      "  File \"/__modal/volumes/vo-05VlmA5Lclgm1HklUu8tDq/monst3r/dust3r/cloud_opt/base_opt.py\", line 494, in global_alignment_loop\n",
      "    loss, flow_loss, lr = global_alignment_iter(net, bar.n, niter, lr_base, lr_min, optimizer, schedule,\n",
      "  File \"/__modal/volumes/vo-05VlmA5Lclgm1HklUu8tDq/monst3r/dust3r/cloud_opt/base_opt.py\", line 569, in global_alignment_iter\n",
      "    loss, flow_loss = net(epoch=cur_iter)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/__modal/volumes/vo-05VlmA5Lclgm1HklUu8tDq/monst3r/dust3r/cloud_opt/optimizer.py\", line 996, in forward\n",
      "    return self.forward_batchify(epoch)\n",
      "  File \"/__modal/volumes/vo-05VlmA5Lclgm1HklUu8tDq/monst3r/dust3r/cloud_opt/optimizer.py\", line 771, in forward_batchify\n",
      "    li = self.dist(proj_pts3d[self._ei], aligned_pred_i, weight=self._weight_i).sum() / self.total_area_i\n",
      "  File \"/__modal/volumes/vo-05VlmA5Lclgm1HklUu8tDq/monst3r/dust3r/cloud_opt/commons.py\", line 72, in l1_dist\n",
      "    return ((a - b).norm(dim=-1) * weight)\n",
      "torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 5.21 GiB. GPU 0 has a total capacity of 79.25 GiB of which 1.52 GiB is free. Process 18 has 77.72 GiB memory in use. Of the allocated memory 72.08 GiB is allocated by PyTorch, and 5.10 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "%cd /root/jupyter/monst3r\n",
    "INPUT_DIR = \"/root/jupyter/data/resized_classified/iphone6/landscape\"\n",
    "OUTPUT_DIR = \"/root/jupyter/data/demo_tmp\"\n",
    "!python demo.py --input {INPUT_DIR} --output_dir {OUTPUT_DIR} --seq_name iphone6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f88a4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/__modal/volumes/vo-05VlmA5Lclgm1HklUu8tDq/monst3r\n",
      "Using device: cuda\n",
      "Outputting results in: /root/jupyter/output\n",
      "Loading weights from checkpoints/MonST3R_PO-TA-S-W_ViTLarge_BaseDecoder_512_dpt.pth\n",
      "... loading model from checkpoints/MonST3R_PO-TA-S-W_ViTLarge_BaseDecoder_512_dpt.pth\n",
      "instantiating : AsymmetricCroCo3DStereo(pos_embed='RoPE100', patch_embed_cls='PatchEmbedDust3R', img_size=(512, 512), head_type='dpt', output_mode='pts3d', depth_mode=('exp', -inf, inf), conf_mode=('exp', 1, inf), enc_embed_dim=1024, enc_depth=24, enc_num_heads=16, dec_embed_dim=768, dec_depth=12, dec_num_heads=12, freeze='encoder', landscape_only=False)\n",
      "Freezing encoder parameters\n",
      "<All keys matched successfully>\n",
      "Starting reconstruction...\n",
      "Loading preprocessed data from '/root/jupyter/data/preprocessed_data.pth'\n",
      ">> Inference with model on 27320 image pairs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27320/27320 [1:04:35<00:00,  7.05it/s]\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------\n",
    "# Imports and setup\n",
    "# --------------------------------------------------------\n",
    "%cd /root/jupyter/monst3r\n",
    "import sys\n",
    "# Add monst3r directory to Python path to find the modules\n",
    "if 'monst3r' not in sys.path:\n",
    "    sys.path.append('monst3r')\n",
    "\n",
    "import argparse\n",
    "import math\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import tempfile\n",
    "import functools\n",
    "import copy\n",
    "\n",
    "from dust3r.inference import inference\n",
    "from dust3r.model import AsymmetricCroCo3DStereo\n",
    "from dust3r.image_pairs import make_pairs\n",
    "from dust3r.utils.image import load_images, load_prev_video_results, rgb, enlarge_seg_masks\n",
    "from dust3r.utils.device import to_numpy\n",
    "from dust3r.cloud_opt import global_aligner, GlobalAlignerMode\n",
    "from dust3r.utils.viz_demo import convert_scene_output_to_glb, get_dynamic_mask_from_pairviewer\n",
    "import matplotlib.pyplot as pl\n",
    "import cv2\n",
    "\n",
    "pl.ion()\n",
    "torch.backends.cuda.matmul.allow_tf32 = True  # for gpu >= Ampere and pytorch >= 1.12\n",
    "\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Function definitions from the Gradio demo script\n",
    "# --------------------------------------------------------\n",
    "\n",
    "def get_3D_model_from_scene(outdir, silent, scene, min_conf_thr=3, as_pointcloud=False, mask_sky=False,\n",
    "                            clean_depth=False, transparent_cams=False, cam_size=0.05, show_cam=True, save_name=None, thr_for_init_conf=True):\n",
    "    \"\"\"\n",
    "    extract 3D_model (glb file) from a reconstructed scene\n",
    "    \"\"\"\n",
    "    if scene is None:\n",
    "        return None\n",
    "    # post processes\n",
    "    if clean_depth:\n",
    "        scene = scene.clean_pointcloud()\n",
    "    if mask_sky:\n",
    "        scene = scene.mask_sky()\n",
    "\n",
    "    # get optimized values from scene\n",
    "    rgbimg = scene.imgs\n",
    "    focals = scene.get_focals().cpu()\n",
    "    cams2world = scene.get_im_poses().cpu()\n",
    "    # 3D pointcloud from depthmap, poses and intrinsics\n",
    "    pts3d = to_numpy(scene.get_pts3d(raw_pts=True))\n",
    "    scene.min_conf_thr = min_conf_thr\n",
    "    scene.thr_for_init_conf = thr_for_init_conf\n",
    "    msk = to_numpy(scene.get_masks())\n",
    "    cmap = pl.get_cmap('viridis')\n",
    "    cam_color = [cmap(i/len(rgbimg))[:3] for i in range(len(rgbimg))]\n",
    "    cam_color = [(255*c[0], 255*c[1], 255*c[2]) for c in cam_color]\n",
    "    return convert_scene_output_to_glb(outdir, rgbimg, pts3d, msk, focals, cams2world, as_pointcloud=as_pointcloud,\n",
    "                                        transparent_cams=transparent_cams, cam_size=cam_size, show_cam=show_cam, silent=silent, save_name=save_name,\n",
    "                                        cam_color=cam_color)\n",
    "\n",
    "def get_reconstructed_scene(args, outdir, model, device, silent, image_size, schedule, niter, min_conf_thr,\n",
    "                            as_pointcloud, mask_sky, clean_depth, transparent_cams, cam_size, show_cam, scenegraph_type, winsize, refid, \n",
    "                            seq_name, new_model_weights, temporal_smoothing_weight, translation_weight, shared_focal, \n",
    "                            flow_loss_weight, flow_loss_start_iter, flow_loss_threshold, use_gt_mask, fps, num_frames):\n",
    "    \"\"\"\n",
    "    from a list of images, run dust3r inference, global aligner.\n",
    "    then run get_3D_model_from_scene\n",
    "    \"\"\"\n",
    "    translation_weight = float(translation_weight)\n",
    "    if new_model_weights != args.weights:\n",
    "        model = AsymmetricCroCo3DStereo.from_pretrained(new_model_weights).to(device)\n",
    "    model.eval()\n",
    "\n",
    "    # <<< YOUR MODIFICATION IS HERE\n",
    "    # Using your specified method to load preprocessed data\n",
    "    print(\"Loading preprocessed data from '/root/jupyter/data/preprocessed_data.pth'\")\n",
    "    imgs = torch.load(\"/root/jupyter/data/preprocessed_data.pth\", weights_only=False)\n",
    "    # >>> END OF MODIFICATION\n",
    "        \n",
    "    if len(imgs) == 1:\n",
    "        imgs = [imgs[0], copy.deepcopy(imgs[0])]\n",
    "        imgs[1]['idx'] = 1\n",
    "    if scenegraph_type == \"swin\" or scenegraph_type == \"swinstride\" or scenegraph_type == \"swin2stride\":\n",
    "        scenegraph_type = scenegraph_type + \"-\" + str(winsize) + \"-noncyclic\"\n",
    "    elif scenegraph_type == \"oneref\":\n",
    "        scenegraph_type = scenegraph_type + \"-\" + str(refid)\n",
    "\n",
    "    pairs = make_pairs(imgs, scene_graph=scenegraph_type, prefilter=None, symmetrize=True)\n",
    "    output = inference(pairs, model, device, batch_size=args.batch_size, verbose=not silent)\n",
    "    \n",
    "    # The rest of the function remains the same...\n",
    "    if len(imgs) > 2:\n",
    "        mode = GlobalAlignerMode.PointCloudOptimizer\n",
    "        scene = global_aligner(output, device=device, mode=mode, verbose=not silent, shared_focal = shared_focal, temporal_smoothing_weight=temporal_smoothing_weight, translation_weight=translation_weight,\n",
    "                               flow_loss_weight=flow_loss_weight, flow_loss_start_epoch=flow_loss_start_iter, flow_loss_thre=flow_loss_threshold, use_self_mask=not use_gt_mask,\n",
    "                               num_total_iter=niter, empty_cache= len(imgs) > 72, batchify=not (args.not_batchify or args.window_wise),\n",
    "                               window_wise=args.window_wise, window_size=args.window_size, window_overlap_ratio=args.window_overlap_ratio,\n",
    "                               prev_video_results=None) # prev_video_results is not used with preprocessed data\n",
    "    else:\n",
    "        mode = GlobalAlignerMode.PairViewer\n",
    "        scene = global_aligner(output, device=device, mode=mode, verbose=not silent)\n",
    "    lr = 0.01\n",
    "\n",
    "    if mode == GlobalAlignerMode.PointCloudOptimizer:\n",
    "        if args.window_wise:\n",
    "            scene.compute_window_wise_alignment(init='mst', niter=niter, schedule=schedule, lr=lr)\n",
    "        else:\n",
    "            scene.compute_global_alignment(init='mst', niter=niter, schedule=schedule, lr=lr)\n",
    "\n",
    "    if args.window_wise and args.prev_output_dir is not None:\n",
    "        scene.clean_prev_results()\n",
    "        \n",
    "    save_folder = f'{args.output_dir}/{seq_name}'\n",
    "    os.makedirs(save_folder, exist_ok=True)\n",
    "    outfile = get_3D_model_from_scene(save_folder, silent, scene, min_conf_thr, as_pointcloud, mask_sky,\n",
    "                            clean_depth, transparent_cams, cam_size, show_cam)\n",
    "\n",
    "    poses = scene.save_tum_poses(f'{save_folder}/pred_traj.txt')\n",
    "    K = scene.save_intrinsics(f'{save_folder}/pred_intrinsics.txt')\n",
    "    depth_maps = scene.save_depth_maps(save_folder)\n",
    "    dynamic_masks = scene.save_dynamic_masks(save_folder)\n",
    "    conf = scene.save_conf_maps(save_folder)\n",
    "    init_conf = scene.save_init_conf_maps(save_folder)\n",
    "    rgbs = scene.save_rgb_imgs(save_folder)\n",
    "    enlarge_seg_masks(save_folder, kernel_size=5 if use_gt_mask else 3) \n",
    "\n",
    "    rgbimg = scene.imgs\n",
    "    depths = to_numpy(scene.get_depthmaps())\n",
    "    confs = to_numpy([c for c in scene.im_conf])\n",
    "    init_confs = to_numpy([c for c in scene.init_conf_maps])\n",
    "    \n",
    "    imgs_for_viz = []\n",
    "\n",
    "    return scene, outfile, imgs_for_viz\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Main execution logic for the notebook\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# 1. Setup arguments (instead of argparse)\n",
    "class Args:\n",
    "    def __init__(self):\n",
    "        # You may need to download the weights first.\n",
    "        # The default path is from the original script.\n",
    "        self.weights = 'checkpoints/MonST3R_PO-TA-S-W_ViTLarge_BaseDecoder_512_dpt.pth'\n",
    "        self.model_name = 'Junyi42/MonST3R_PO-TA-S-W_ViTLarge_BaseDecoder_512_dpt'\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        self.output_dir = '/root/jupyter/output'\n",
    "        self.prev_output_dir = None\n",
    "        self.prev_output_index = None\n",
    "        self.silent = False\n",
    "        # # --- IMPORTANT: Change this to your image folder or video file ---\n",
    "        # self.input_dir = '/root/jupy' \n",
    "        self.seq_name = 'huaca' # This will be the output subfolder name\n",
    "        self.use_gt_davis_masks = False\n",
    "        self.not_batchify = False\n",
    "        self.real_time = False\n",
    "        self.window_wise = False\n",
    "        self.window_size = 100\n",
    "        self.window_overlap_ratio = 0.5\n",
    "        self.batch_size = 100 # Lower this if you get CUDA out-of-memory errors\n",
    "        self.fps = 0\n",
    "        self.num_frames = 200\n",
    "        self.image_size = 512\n",
    "\n",
    "args = Args()\n",
    "\n",
    "# Create output directory\n",
    "tmpdirname = args.output_dir\n",
    "os.makedirs(tmpdirname, exist_ok=True)\n",
    "tempfile.tempdir = tmpdirname\n",
    "\n",
    "print(f'Using device: {args.device}')\n",
    "print('Outputting results in:', tmpdirname)\n",
    "\n",
    "# 2. Load model\n",
    "if args.weights and os.path.exists(args.weights):\n",
    "    weights_path = args.weights\n",
    "    print(f\"Loading weights from {weights_path}\")\n",
    "else:\n",
    "    print(f\"Weights file not found at '{args.weights}'. Attempting to load from Hugging Face Hub model name '{args.model_name}'.\")\n",
    "    weights_path = args.model_name\n",
    "\n",
    "model = AsymmetricCroCo3DStereo.from_pretrained(weights_path).to(args.device)\n",
    "model.eval()\n",
    "\n",
    "\n",
    "# 4. Run reconstruction\n",
    "print(\"Starting reconstruction...\")\n",
    "scene, outfile, imgs = get_reconstructed_scene(\n",
    "    args=args,\n",
    "    outdir=tmpdirname,\n",
    "    model=model,\n",
    "    device=args.device,\n",
    "    silent=args.silent,\n",
    "    image_size=args.image_size,\n",
    "    # filelist=input_files,\n",
    "    schedule='linear',\n",
    "    niter=300,\n",
    "    min_conf_thr=1.1,\n",
    "    as_pointcloud=True,\n",
    "    mask_sky=False,\n",
    "    clean_depth=True,\n",
    "    transparent_cams=False,\n",
    "    cam_size=0.05,\n",
    "    show_cam=True,\n",
    "    scenegraph_type='swinstride',\n",
    "    winsize=5,\n",
    "    refid=0,\n",
    "    seq_name=args.seq_name,\n",
    "    new_model_weights=args.weights,\n",
    "    temporal_smoothing_weight=0.01,\n",
    "    translation_weight='1.0',\n",
    "    shared_focal=True,\n",
    "    flow_loss_weight=0.01,\n",
    "    flow_loss_start_iter=0.1,\n",
    "    flow_loss_threshold=25,\n",
    "    use_gt_mask=args.use_gt_davis_masks,\n",
    "    fps=args.fps,\n",
    "    num_frames=args.num_frames,\n",
    ")\n",
    "\n",
    "print(\"\\nProcessing completed.\")\n",
    "print(f\"Output maps and data saved in: {os.path.join(tmpdirname, args.seq_name)}\")\n",
    "if outfile:\n",
    "    print(f\"3D model saved to: {outfile}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "117839d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download_bonn.sh             download_spring.sh\n",
      "download_ckpt.sh             download_tartanair.py\n",
      "download_davis.py            download_tartanair.sh\n",
      "download_dynamic_replica.sh  download_training_zipfiles.txt\n",
      "download_kitti.sh            download_tum_dynamics.sh\n",
      "download_nyuv2.sh            download_waymo.sh\n",
      "download_pointodyssey.sh     evaluation_script.md\n",
      "download_scannetv2.sh        prepare_training.md\n",
      "download_sintel.sh\n"
     ]
    }
   ],
   "source": [
    "%ls /root/jupyter/monst3r/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3159e5a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/__modal/volumes/vo-05VlmA5Lclgm1HklUu8tDq/monst3r/data\n",
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1Z1jO_JmfZj0z3bgMvCwqfUhyZ1bIbc9E\n",
      "From (redirected): https://drive.google.com/uc?id=1Z1jO_JmfZj0z3bgMvCwqfUhyZ1bIbc9E&confirm=t&uuid=12fabc9d-a0ec-40a2-adfa-0017fd7efa7c\n",
      "To: /__modal/volumes/vo-05VlmA5Lclgm1HklUu8tDq/monst3r/checkpoints/MonST3R_PO-TA-S-W_ViTLarge_BaseDecoder_512_dpt.pth\n",
      "100%|██████████████████████████████████████| 2.29G/2.29G [00:28<00:00, 81.2MB/s]\n",
      "--2025-10-14 17:33:27--  https://www.dropbox.com/s/4j4z58wuv8o0mfz/models.zip\n",
      "Resolving www.dropbox.com (www.dropbox.com)... 162.125.11.18, 2620:100:6050:18::a27d:b12\n",
      "Connecting to www.dropbox.com (www.dropbox.com)|162.125.11.18|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://www.dropbox.com/scl/fi/1gtoiul6tr71ag8xjet5v/models.zip?rlkey=lu59i7g742lo6o2yt15f8t96r [following]\n",
      "--2025-10-14 17:33:28--  https://www.dropbox.com/scl/fi/1gtoiul6tr71ag8xjet5v/models.zip?rlkey=lu59i7g742lo6o2yt15f8t96r\n",
      "Reusing existing connection to www.dropbox.com:443.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://uc38665a6547f99fd4b0bbfd718d.dl.dropboxusercontent.com/cd/0/inline/CzNanDkioYeyqFLayLphtccQ-r52b_OZuPQrwEVtYs_S52nI3jYS6M6RdOSRVZDpiM5-xofU9aCw8ApDNccQ-EnJ0XfWR_zFo1utggsfijlWlwxCW_PdfKtmlfHatQVqgT1kKqEc11kKV_t7jYGDlmvg/file# [following]\n",
      "--2025-10-14 17:33:28--  https://uc38665a6547f99fd4b0bbfd718d.dl.dropboxusercontent.com/cd/0/inline/CzNanDkioYeyqFLayLphtccQ-r52b_OZuPQrwEVtYs_S52nI3jYS6M6RdOSRVZDpiM5-xofU9aCw8ApDNccQ-EnJ0XfWR_zFo1utggsfijlWlwxCW_PdfKtmlfHatQVqgT1kKqEc11kKV_t7jYGDlmvg/file\n",
      "Resolving uc38665a6547f99fd4b0bbfd718d.dl.dropboxusercontent.com (uc38665a6547f99fd4b0bbfd718d.dl.dropboxusercontent.com)... 162.125.11.15, 2620:100:6050:15::a27d:b0f\n",
      "Connecting to uc38665a6547f99fd4b0bbfd718d.dl.dropboxusercontent.com (uc38665a6547f99fd4b0bbfd718d.dl.dropboxusercontent.com)|162.125.11.15|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: /cd/0/inline2/CzPUYSJOcjGj0vo4CZO5JXgBZnNNrN0cUQiv6m0aYzfyqYo-hFM9uEd52wzGqKgcTmxs7JQqXCx5bilY5tb99T7mwaRZ3VQUoX06WVQ0yKXS_D12Onh_14prR9bjsxuwDUfKu8RNyYTwFdMSnu285lOvpVkKcCMgFJRt8IYyWcTh0fyOehFMPIMDdNE_L2TYl5dmkuc5aEf26w4zX-7h9t2iPMY7z2TCQcYc_8pP0MZqBTOqO4vP1g4mn043R5TfMFjmwNWCH1H7OPCKlQuGUFri-ZeqjIhj8t0a6U_zDeEsuGmtbAuBjwMBP1HB5CX6YKToy7swLXyTEtn3apaPMdcIbfag9bjvO9lIkMxnkF4guxvaXsszH_IjPzs04JXYp04/file [following]\n",
      "--2025-10-14 17:33:29--  https://uc38665a6547f99fd4b0bbfd718d.dl.dropboxusercontent.com/cd/0/inline2/CzPUYSJOcjGj0vo4CZO5JXgBZnNNrN0cUQiv6m0aYzfyqYo-hFM9uEd52wzGqKgcTmxs7JQqXCx5bilY5tb99T7mwaRZ3VQUoX06WVQ0yKXS_D12Onh_14prR9bjsxuwDUfKu8RNyYTwFdMSnu285lOvpVkKcCMgFJRt8IYyWcTh0fyOehFMPIMDdNE_L2TYl5dmkuc5aEf26w4zX-7h9t2iPMY7z2TCQcYc_8pP0MZqBTOqO4vP1g4mn043R5TfMFjmwNWCH1H7OPCKlQuGUFri-ZeqjIhj8t0a6U_zDeEsuGmtbAuBjwMBP1HB5CX6YKToy7swLXyTEtn3apaPMdcIbfag9bjvO9lIkMxnkF4guxvaXsszH_IjPzs04JXYp04/file\n",
      "Reusing existing connection to uc38665a6547f99fd4b0bbfd718d.dl.dropboxusercontent.com:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 81977417 (78M) [application/zip]\n",
      "Saving to: ‘models.zip’\n",
      "\n",
      "models.zip          100%[===================>]  78.18M  29.3MB/s    in 2.7s    \n",
      "\n",
      "2025-10-14 17:33:32 (29.3 MB/s) - ‘models.zip’ saved [81977417/81977417]\n",
      "\n",
      "Archive:  models.zip\n",
      "   creating: models/\n",
      "  inflating: models/raft-kitti.pth   \n",
      "  inflating: models/raft-sintel.pth  \n",
      "  inflating: models/raft-chairs.pth  \n",
      "  inflating: models/raft-things.pth  \n",
      "  inflating: models/raft-small.pth   \n",
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1a0C5FTdhjM4rKrfXiGhec7eq2YM141lu\n",
      "From (redirected): https://drive.google.com/uc?id=1a0C5FTdhjM4rKrfXiGhec7eq2YM141lu&confirm=t&uuid=7d8da83a-766c-4f43-bbf8-0b331677221a\n",
      "To: /__modal/volumes/vo-05VlmA5Lclgm1HklUu8tDq/monst3r/third_party/RAFT/models/Tartan-C-T-TSKH-spring540x960-M.pth\n",
      "100%|██████████████████████████████████████| 78.9M/78.9M [00:00<00:00, 81.4MB/s]\n",
      "--2025-10-14 17:33:36--  https://dl.fbaipublicfiles.com/segment_anything_2/092824/sam2.1_hiera_large.pt\n",
      "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 3.160.22.125, 3.160.22.85, 3.160.22.80, ...\n",
      "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|3.160.22.125|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 898083611 (856M) [application/vnd.snesdev-page-table]\n",
      "Saving to: ‘checkpoints/sam2.1_hiera_large.pt’\n",
      "\n",
      "sam2.1_hiera_large. 100%[===================>] 856.48M  19.6MB/s    in 45s     \n",
      "\n",
      "2025-10-14 17:34:21 (19.2 MB/s) - ‘checkpoints/sam2.1_hiera_large.pt’ saved [898083611/898083611]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%cd /root/jupyter/monst3r/data\n",
    "!bash download_ckpt.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0281a3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download_bonn.sh             download_spring.sh\n",
      "download_ckpt.sh             download_tartanair.py\n",
      "download_davis.py            download_tartanair.sh\n",
      "download_dynamic_replica.sh  download_training_zipfiles.txt\n",
      "download_kitti.sh            download_tum_dynamics.sh\n",
      "download_nyuv2.sh            download_waymo.sh\n",
      "download_pointodyssey.sh     evaluation_script.md\n",
      "download_scannetv2.sh        prepare_training.md\n",
      "download_sintel.sh\n"
     ]
    }
   ],
   "source": [
    "%ls /root/jupyter/monst3r/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "81c268fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mCUT3R\u001b[0m/  \u001b[01;34mdata\u001b[0m/  \u001b[01;34mmonst3r\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "%ls /root/jupyter/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c633855e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
