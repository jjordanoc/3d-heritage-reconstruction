{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b433b24",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "git clone --recursive https://github.com/junyi42/monst3r /root/jupyter/monst3r\n",
    "cd monst3r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4cf4ca",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# DUST3R relies on RoPE positional embeddings for which you can compile some cuda kernels for faster runtime.\n",
    "cd croco/models/curope/\n",
    "python setup.py build_ext --inplace\n",
    "cd ../../../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3896357b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def get_3D_model_from_scene(outdir, silent, scene, min_conf_thr=3, as_pointcloud=False, mask_sky=False,\n",
    "                            clean_depth=False, transparent_cams=False, cam_size=0.05, show_cam=True, save_name=None, thr_for_init_conf=True):\n",
    "    \"\"\"\n",
    "    extract 3D_model (glb file) from a reconstructed scene\n",
    "    \"\"\"\n",
    "    if scene is None:\n",
    "        return None\n",
    "    # post processes\n",
    "    if clean_depth:\n",
    "        scene = scene.clean_pointcloud()\n",
    "    if mask_sky:\n",
    "        scene = scene.mask_sky()\n",
    "\n",
    "    # get optimized values from scene\n",
    "    rgbimg = scene.imgs\n",
    "    focals = scene.get_focals().cpu()\n",
    "    cams2world = scene.get_im_poses().cpu()\n",
    "    # 3D pointcloud from depthmap, poses and intrinsics\n",
    "    pts3d = to_numpy(scene.get_pts3d(raw_pts=True))\n",
    "    scene.min_conf_thr = min_conf_thr\n",
    "    scene.thr_for_init_conf = thr_for_init_conf\n",
    "    msk = to_numpy(scene.get_masks())\n",
    "    cmap = pl.get_cmap('viridis')\n",
    "    cam_color = [cmap(i/len(rgbimg))[:3] for i in range(len(rgbimg))]\n",
    "    cam_color = [(255*c[0], 255*c[1], 255*c[2]) for c in cam_color]\n",
    "    return convert_scene_output_to_glb(outdir, rgbimg, pts3d, msk, focals, cams2world, as_pointcloud=as_pointcloud,\n",
    "                                        transparent_cams=transparent_cams, cam_size=cam_size, show_cam=show_cam, silent=silent, save_name=save_name,\n",
    "                                        cam_color=cam_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf4f058",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_reconstructed_scene(args, outdir, model, device, silent, image_size, filelist, schedule, niter, min_conf_thr,\n",
    "                            as_pointcloud, mask_sky, clean_depth, transparent_cams, cam_size, show_cam, scenegraph_type, winsize, refid, \n",
    "                            seq_name, new_model_weights, temporal_smoothing_weight, translation_weight, shared_focal, \n",
    "                            flow_loss_weight, flow_loss_start_iter, flow_loss_threshold, use_gt_mask, fps, num_frames):\n",
    "    \"\"\"\n",
    "    from a list of images, run dust3r inference, global aligner.\n",
    "    then run get_3D_model_from_scene\n",
    "    \"\"\"\n",
    "    translation_weight = float(translation_weight)\n",
    "    if new_model_weights != args.weights:\n",
    "        model = AsymmetricCroCo3DStereo.from_pretrained(new_model_weights).to(device)\n",
    "    model.eval()\n",
    "    if seq_name != \"NULL\":\n",
    "        dynamic_mask_path = f'data/davis/DAVIS/masked_images/480p/{seq_name}'\n",
    "    else:\n",
    "        dynamic_mask_path = None\n",
    "\n",
    "    imgs = torch.load(\"/root/jupyter/data/preprocessed_data.pth\")\n",
    "        \n",
    "    if len(imgs) == 1:\n",
    "        imgs = [imgs[0], copy.deepcopy(imgs[0])]\n",
    "        imgs[1]['idx'] = 1\n",
    "    if scenegraph_type == \"swin\" or scenegraph_type == \"swinstride\" or scenegraph_type == \"swin2stride\":\n",
    "        scenegraph_type = scenegraph_type + \"-\" + str(winsize) + \"-noncyclic\"\n",
    "    elif scenegraph_type == \"oneref\":\n",
    "        scenegraph_type = scenegraph_type + \"-\" + str(refid)\n",
    "\n",
    "    pairs = make_pairs(imgs, scene_graph=scenegraph_type, prefilter=None, symmetrize=True)\n",
    "    output = inference(pairs, model, device, batch_size=args.batch_size, verbose=not silent)\n",
    "    # TODO YYJ del model\n",
    "    if len(imgs) > 2:\n",
    "        mode = GlobalAlignerMode.PointCloudOptimizer\n",
    "        scene = global_aligner(output, device=device, mode=mode, verbose=not silent, shared_focal = shared_focal, temporal_smoothing_weight=temporal_smoothing_weight, translation_weight=translation_weight,\n",
    "                               flow_loss_weight=flow_loss_weight, flow_loss_start_epoch=flow_loss_start_iter, flow_loss_thre=flow_loss_threshold, use_self_mask=not use_gt_mask,\n",
    "                               num_total_iter=niter, empty_cache= len(filelist) > 72, batchify=not (args.not_batchify or args.window_wise),\n",
    "                               window_wise=args.window_wise, window_size=args.window_size, window_overlap_ratio=args.window_overlap_ratio,\n",
    "                               prev_video_results=prev_video_results)\n",
    "    else:\n",
    "        mode = GlobalAlignerMode.PairViewer\n",
    "        scene = global_aligner(output, device=device, mode=mode, verbose=not silent)\n",
    "    lr = 0.01\n",
    "\n",
    "    if mode == GlobalAlignerMode.PointCloudOptimizer:\n",
    "        if args.window_wise:\n",
    "            scene.compute_window_wise_alignment(init='mst', niter=niter, schedule=schedule, lr=lr)\n",
    "        else:\n",
    "            scene.compute_global_alignment(init='mst', niter=niter, schedule=schedule, lr=lr)\n",
    "\n",
    "    if args.window_wise and args.prev_output_dir is not None:\n",
    "        scene.clean_prev_results()\n",
    "        \n",
    "    save_folder = f'{args.output_dir}/{seq_name}'  #default is 'demo_tmp/NULL'\n",
    "    os.makedirs(save_folder, exist_ok=True)\n",
    "    outfile = get_3D_model_from_scene(save_folder, silent, scene, min_conf_thr, as_pointcloud, mask_sky,\n",
    "                            clean_depth, transparent_cams, cam_size, show_cam)\n",
    "\n",
    "    poses = scene.save_tum_poses(f'{save_folder}/pred_traj.txt')\n",
    "    K = scene.save_intrinsics(f'{save_folder}/pred_intrinsics.txt')\n",
    "    depth_maps = scene.save_depth_maps(save_folder)\n",
    "    dynamic_masks = scene.save_dynamic_masks(save_folder)\n",
    "    conf = scene.save_conf_maps(save_folder)\n",
    "    init_conf = scene.save_init_conf_maps(save_folder)\n",
    "    rgbs = scene.save_rgb_imgs(save_folder)\n",
    "    enlarge_seg_masks(save_folder, kernel_size=5 if use_gt_mask else 3) \n",
    "\n",
    "    # also return rgb, depth and confidence imgs\n",
    "    # depth is normalized with the max value for all images\n",
    "    # we apply the jet colormap on the confidence maps\n",
    "    rgbimg = scene.imgs\n",
    "    depths = to_numpy(scene.get_depthmaps())\n",
    "    confs = to_numpy([c for c in scene.im_conf])\n",
    "    init_confs = to_numpy([c for c in scene.init_conf_maps])\n",
    "    cmap = pl.get_cmap('jet')\n",
    "    depths_max = max([d.max() for d in depths])\n",
    "    depths = [cmap(d/depths_max) for d in depths]\n",
    "    confs_max = max([d.max() for d in confs])\n",
    "    confs = [cmap(d/confs_max) for d in confs]\n",
    "    init_confs_max = max([d.max() for d in init_confs])\n",
    "    init_confs = [cmap(d/init_confs_max) for d in init_confs]\n",
    "\n",
    "    imgs = []\n",
    "    for i in range(len(rgbimg)):\n",
    "        imgs.append(rgbimg[i])\n",
    "        imgs.append(rgb(depths[i]))\n",
    "        imgs.append(rgb(confs[i]))\n",
    "        imgs.append(rgb(init_confs[i]))\n",
    "\n",
    "    # if two images, and the shape is same, we can compute the dynamic mask\n",
    "    if len(rgbimg) == 2 and rgbimg[0].shape == rgbimg[1].shape:\n",
    "        motion_mask_thre = 0.35\n",
    "        error_map = get_dynamic_mask_from_pairviewer(scene, both_directions=True, output_dir=args.output_dir, motion_mask_thre=motion_mask_thre)\n",
    "        # imgs.append(rgb(error_map))\n",
    "        # apply threshold on the error map\n",
    "        normalized_error_map = (error_map - error_map.min()) / (error_map.max() - error_map.min())\n",
    "        error_map_max = normalized_error_map.max()\n",
    "        error_map = cmap(normalized_error_map/error_map_max)\n",
    "        imgs.append(rgb(error_map))\n",
    "        binary_error_map = (normalized_error_map > motion_mask_thre).astype(np.uint8)\n",
    "        imgs.append(rgb(binary_error_map*255))\n",
    "\n",
    "    return scene, outfile, imgs"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
